resultaat vraag 1: ( met aparte train en test, dus geen cross-validation)

 accuracy score: 0.8313333333333334



              precision    recall  f1-score   support

         neg       0.82      0.84      0.83       731
         pos       0.85      0.82      0.83       769

    accuracy                           0.83      1500
   macro avg       0.83      0.83      0.83      1500
weighted avg       0.83      0.83      0.83      1500


 Confusion Matrix

[[617 114]
 [139 630]]


Vraag 2:

Info voor in report:
the C parameter tells the SVM optimization how much you want to
avoid misclassifying each training example.
The higher C, the largest the penalty to errors.

large values of C: large penalty to errors; the optimization will
choose a smaller-margin hyperplane if that hyperplane does a
better job of getting all the training points classified correctly

a very small value of C: the optimizer will look for a larger-margin
separating hyperplane, even if that hyperplane misclassifies more
points.

very very tiny values of C: you are likely to get misclassified
examples, often even if your training data is linearly separable.

c = 0.1: 0.794
c= 0.5:  0.8266666666666667
c = 0.6: 0.8313333333333334
c = 0.7: 0.8326666666666667 ( hoger ) 
c = 0.8: 0.8346666666666667 ( hoogst ) 
c = 0.9:  0.8326666666666667 ( hoger) 
c= 1 : 0.8313333333333334 (standaard)
c = 1.1:  0.8306666666666667
c = 1.2:  0.83
c = 1.5: 0.8293333333333334
c = 2: 0.8313333333333334
c = 3: 0.8173333333333334
c = 5:  0.8106666666666666
c = 10 : 0.8106666666666666
c = 15:  0.8106666666666666
c = 20:  0.8106666666666666


Vraag 3:

Rbf score: 0.8333333333333334 (bijna hetzelfde) (gamma 0.7, c 1)
 the gamma parameter defines how far the influence of a single training example reaches, with low values meaning ‘far’ and high values meaning ‘close’

gamma 0.1, c 1 : 0.8166666666666667
gamma 0.3, c 1: 0.828
gamma 0.5, c 1: 0.8346666666666667
gamma 0.6, c1     0.8346666666666667
gamma 1, c 1:     0.834
gamma 10, c1:     0.5026666666666667
gamma 5,c1:      0.528
gamma 2, c1:      0.8233333333333334
gamma 1.5, c1:     0.8313333333333334

gamma 0.5, c 0.8: 0.8293333333333334
gamma 0.6, c 1.5: 0.8326666666666667

... c2: 0.8353333333333334
... c3: 0.8353333333333334
gamma 0.8, c4:  0.8406666666666667
gamma 0.8, c3.5:  0.8406666666666667
gamma 0.8, c3:  0.8413333333333334 (hoogst)
gamma 0.8, c2: 0.84

gamma 1, c3:0.8413333333333334
gamma 1, c4: 0.8413333333333334
gamma 1.1, c3: 0.838
gamma 1.5, c3:0. 0.8373333333333334
gamma 1, c2: 0.8393333333333334


Vraag 4: 
https://intellipaat.com/community/19783/which-one-is-better-linearsvc-or-svc#:~:text=The%20key%20principles%20of%20that,for%20loss%20parameter%20in%20LinearSVC. 

Linear is veel sneller. c1 = 0.8333333333333334, c2 = 0.8266666666666667, c1.5 = 0.828
( This is due to the fact that the linear kernel is a special case, which is optimized for in Liblinear, but not in Libsvm.)

But after I change LinearSVC to SVC(kernel=’linear’), the program couldn’t work out any result even after 12 hours!
Am I doing anything wrong? In the page of sklearn.svm.LinearSVC, there is a note:

Similar to SVC with parameter kernel=’linear’, but implemented in terms of liblinear rather than libsvm, so it has more flexibility in the choice of penalties and loss functions and should scale better to large numbers of samples.

Also in the page of sklearn.svm.SVC, it’s another note:

The implementation is based on libsvm. The fit time complexity is more than quadratic with the number of samples which makes it hard to scale to dataset with more than a couple of 10000 samples.

That’s the answer: LinearSVC is the right choice to process a large number of samples.




Vraag 5: it is highly recommended to scale your data (stond ergens in een scikit linkje) 
